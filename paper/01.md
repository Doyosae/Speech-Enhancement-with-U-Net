# Supervised Speech Separation Based on Deep Learning: An Overview (DeLiang Wang, Fellow, IEEE, and Jitong Chen)  
## 요약  
최근의 접근 방법은 speech separation를 supervised learning problem으로 공식화한다.  
이렇게 지도 학습으로 푸는 것은 훈련 데이터로부터 음성, 화자, 배경 노이즈로부터 구별 가능한 패턴을 학습하는 것이다.  
음원 분리의 목표는 방해 background interference로부터 target speech를 분리하는 것이다.  
사람은 여러 음원 소스가 섞여 있어도, 듣고 싶은 것을 잘 듣는다. 그래서 음원 분리는 곧 칵테일 문제와 같다.  
#
#
## 개요  
어떻게 음원 분리를 잘 해낼 수 있을까? 그 중 한가지 방법은 50% intelligibility score를 위해 필요한 SNR 수준에서 음성 수신 임계값을 측정하는 것이다. 서로 다른 interference로부터 SRT 값의 차이가 매우 크게 난다. (SRT는 50% 점수를 위한 SNR 값) 지난 수 십년간 음성 분리는 신호 처리 영역에서 연구되었는데, 센서와 마이크로 폰의 갯수에 의존하는 방법으로는 아래와 같다.  
- Monaural (single microphone)  
- Array based (multi microphone)  
#
Monaural seperation을 위한 두 전통적인 방법은 Speech enhancement와 CASA이다. Speech enhancement는 노이즈의 일반적인 통계를 분석하고, 추정한 소음을 포함하는 음원에서 깨끗한 speech를 걸러낸다. 이러한 알고리즘으로 spectrum substraction이 유명하다. 이것은 추정한 노이즈의 강력한 스펙트럼이 노이즈가 낀 speech에서 빠진다. 이때 가정을 하나 한다. 배경 노이즈가 정적이라는 것이다. 하다못해 최소한 speech보다 정적이여야 한다. CASA (computational auditory scene analysis)는 청각 장면 분석의 지각 원리에 기초한다. 그리고 pitch와 onset과 같은 그룹화된 큐들을 적극 이용한다.
#
두 개 이상의 마이크가 있는 경우는 speech seperation을 위한 다른 원리를 사용한다. Beamforming 또는 공간 필터링이라는 방법은 적절한 배열 구성을 통해, 특정 방향에 도달하는 신호를 가속시킨다. (증폭?) 그렇게 함으로써 다른 방향에서 오는 간섭을 감소시킨다. 이러한 노이즈 감쇠의 양은 일반적으로 어레이의 간격, 크기 및 구성에 따라 달라진다. 보다 최근의 방법은 speech seperation을 지도 학습 문제로 다루는 것이다. 지도 음성 분리의 원래 방식은 CASA에서 time frequency masking의 개념에서 영감을 받았다. 분리 수단으로, TF 마스킹은 목표하는 소스를 분리하기 위해, 섞인 소스의 TF 표현에다가 2차원 마스크를 (가중치) 적용한다. CASA의 주요 목표는 이상적인 바이너리 마스크이다. 이 마스크는 섞인 신호의 TF 표현에서 목표하는 신호가 TF unit을 지배하는지 여부를 나타낸다. 위에서 말한 이상적인 바이너리 마스크가 목표라면, 음성 분리는 지도 학습으로 수행되는 이진 분류 문제가 된다.  
#
음성 분리를 분류 문제로 보기 시작하면서, 데이터 기반 접근법은 음성 처리 커뮤니티에서 넓게 연구되어 왔다. 지난 10년 동안 지도 음성 분리는 최첨단 성능을 크게 향상시켰다. 지도 학습 분리는 특히 딥 러닝의 성장으로부터 큰 혜택을 보았다. 앞으로 볼테지만 말이다. 지도 학습 기반 음성 분리 알고리즘은 크게 학습하는 기계, 교육하는 대상, 음향학적 특징으로 나눌 수 있다. 이 문서에서는 먼저 세 가지 구성 요소를 검토하고, 별도로 monural 및 array 기반 대표적인 알고리즘을 설명한다.  
#
#
## Section II, 분류기와 학습하는 기계  
심층 신경망은 지난 10년간 많은 지도 학습 작업의 성능을 크게 높였다. 지도 학습 기반 Speech seperation을 위한 심층 신경망은 큰 이점을 가지고 왔는데, 이 논문에서는 MLP, CNN, RNN, GAN 모델들을 검토한다. ... ... 라고 하지만 신경망 종류와 기초적인 내용들이라 이미 다 알고 있으므로 자세히는 패스... 
DNN에서 크로스 엔트로피는 보편적인 손실함수이고, 회귀 분석에서의 손실함수는 MSE를 쓴다. 파라미터의 초기화 문제와 그래디언트 배니싱 문제가 있다. 레이어가 깊어지면서 미분값을을 많이 곱하여 오차를 줄이다보니, 그 값이 0에 수렴해서 파라미터 업데이트가 안되는 현상이다. 비선형 활성함수를 도입해서 이러한 문제를 해결할 수 있다. 이를테면 ReLU 같은 것들이다. (그 다음 문단에서는 합성곱 신경망에 대하여 설명한다. 이 신경망은 지금도 많이 사용하므로 설명을 패스한다. GAN도 현재 계속 공부하고 있으므로 자세한 내용은 생략한다. 참고로 오리지널 GAN은 KL Divergence의 한계가 있어서, 나중의 GAN에서는 전혀 다른 거리 함수를 정의하여 모델이 나왔다.)
#
(RNN은 그리 많이 사용해보지 않았다. 그래서 이 부분은 짚고 넘어간다.) RNN은 숨겨진 단위 사이에서 연결되는 재귀 신경망이다. 피드포워드 신경망과는 달리 RNN은 입력 샘플을 Sequence로 처리하고, 시간에 따라 변하는 모델이다. 사실 음성 신호라는 것이 시간 도메인을 기반으로 한 구조이고, 현재 프레임에 있는 신호는 이전 프레임의 신호에 영향을 받는다. 그러므로 음성의 시간에 의존하는 성질 때문에 RNN을 선택하는 것은 매우 자연스럽다. 우리는 반복적인 연결을 통해 RNN이 유연하고 무한히 확장 가능한 시간 차원을 도입한다는 것에 주목한다. 이 특징은 DNN와는 달리 아무리 깊더라도 문제가 되지 않는다. 재귀 신경망 역시 시간을 통한 backpropagation으로 학습한다. 그러나 RNN 역시 그래디언트 배니싱 또는 폭발 문제로부터 자유롭지 못하다. 이를 개선한 모델이 LSTM이다. LSTM은 시간이 오래 지난 정보는 잊어버려서 정보 흐름이 원활하다. 이 LSTM의 메모리 셀에는 입력 게이트, 망각 게이트, 출력 게이트 세 가지로 구성되어 있다. 망각 게이트는 이전 정보를 얼마나 보존해야 하는지 제어한다. 그리고 입력 게이트는 얼마나 현재 정보가 메모리 셀에 추가되어야 하는지 제어한다. 이러한 게이트 기능으로 LSTM은 맥락과 연관된 정보를 메모리 셀에 유지하여 RNN 성능을 향상시킨다. 여하튼 우리는 이제 히든 레이어를 가진 DNN을 Speech seperation을 위한 기계로 논의한다. 서포트 벡터 머신이나, 믹스처 가우시안 모델 등과 같이 전통적인 머신러닝 모델들은 앞으로 논의 하지 않는다.  
#
#
## III. 훈련 대상  
지도 학습 기반 음성 분리에서 학습과 일반화를 위해 적절한 훈련 대상을 찾는 것이 중요하다. 훈련 대상은 주로 마스킹 기반 대상과 매핑 기반 대상으로 나눈다. 마스킹 기반 대상은 배경 간섭으로부터 깨끗한 음성의 시간 - 주파수 관계를 설명한다. 반면에 매핑 기반 대상은 깨끗한 음성의 스펙트럼 표현에 해당한다.  
#
훈련 대상을 설명하기에 앞서, 먼저 음성 분리에서 흔히 사용하는 평가 메트릭에 대해 이야기한다. 메트릭들은 두 가지로 구분이 가능하다. 하나는 신호 레벨이고 다른 하나는 인식 레벨이다. 신호 레벨에서 메트릭은 신호 향상 또는 간섭 감소의 정도를 정량화하는 것을 목표한다. 대표적인 평가 메트릭 집합은 신호 대 왜곡, 신호 대 간섭, 신호 대 아티팩트 비율로 이루어진다. 객관적인 메트릭들이 음성의 명료성과 음성의 품질의 평가를 분리하기 위하여 개발되었다. HIT는 정확하게 분류된 IBM에서 음성을 지배하는 시간 - 주파수 유닛의 백분율을 보여준다. FA은 (False Alarm) 잘못 분류된 노이즈를 지배하는 유닛의 백분율을 보여준다. 그래서 HIT - FA는 음성의 명료성에서 잘 작동한다. 왜? 각 유닛에서 노이즈가 지배적인지 음성이 지배적의 지표이므로. 
#  
최근에 흔히 사용하는 명료성 평가 메트릭은 shot time objective intelligibility이다. 이것은 추론한 발성과 분리된 발성의 short time temporal envelopes 간의 상관관계를 측정한다. 음성 품질에 대해서는 ITU가 권장하는 PESQ가 표준 평가 지표이다. PESQ는 음량 스펙트럼을 생성하기 위해 audiotory transform을 적용한다. 그리고 깨끗한 추론 신호와 분리된 신호의 음량 스펙트럼을 비교하여 -0.5에서 4.5 사이의 점수를 산출한다.  
### A. Ideal Binary Mask (IBM)  
IBM은 청각 장면 해석의 독점 할당 원리와 오디션에서의 청각적 마스킹 현상에 영감을 얻었다. 
IBM은 노이즈가 낀 신호의 시간 - 주파수 표현에서 정의된다. (예를 들면 스펙토그램) 
IBM은 시간 - 주파수 단위 안에서 SNR이 로컬 기준 내지 임계값보다 크면, 그 단위에 1을 할당한다.  
IBM은 청각 장애를 위해 음성의 명료성을 획기적으로 향상시킨다. (1 아니면 0이므로, 바이너리) 
IBM은 모든 시간 - 주파수 유닛에 target-dominant이든 interference-dominannt이든 이름을 붙인다. 
결과적으로 IBM의 추정은 지도 학습으로 다룰 수 있다. (타겟이냐? 간섭이냐? 문제) 
IBM의 추정을 위해 사용되는 비용 함수는 보통 cross entorpy이다.  
### B. Target Binary Mask (TBM)
IBM처럼, TBM은 모든 시간 - 주파수 단위를 이진 레이블로 분류한다. 차이점이라면 TBM은 각각의 시간 - 주파수 단위에서 목표 음성 에너지와 고정 간섭을 비교하여 레이블을 얻는다. 이 고정 간섭은 노이즈 형태의 음성인데, 모든 음성 신호의 평균과 일치하는 정지 신호이다. (앞에서 간섭이 정지 신호여야 한다는 가정과 일치함, 모든 신호의 평균은 사실상 정지 신호?) TBM 역시 음성의 명료성을 획기적으로 향상시킨다.  
### C. Ideal Ratio Mask  
각 TF 단위의 하드한 라벨링 대신, IRM은 IBM의 부드러운 버전이다. 이것은 TF 단위 내의 음성 에너지와 노이즈 에너지를 이용한다. 튜닝 가능한 파라미터는 리스케일링 하여 0.5로 선택한다. S와 N이 상관없다는 가정 하에 IRM의 제곱근은 TF 유닛의 음성 에너지를 보존한다. 이 가정은 겹쳐진 노이즈에는 적합하지만, 실내 반향같이 난향성 노이즈에는 적합하지 않다. 제곱근이 없다면 IRM은 세기 스펙트럼에서 대상 음성의 최적의 추정기인 Winer filter와 유사하다. MSE가 일반적으로 IRM 추정의 비용 함수로 쓰인다. 
### D. Sepctrum Magnitude Mask
스펙트럼 크기 마스크 SMM은 깨끗한 음성과 노이즈 음성의 진폭을 STFT 하는 것에서 정의된다. 수식 표현에서 S(t, f)와 Y(t, f)는 각각 깨끗한 음성의 스펙트럼 크기와 노이즈 음성 스펙트럼의 크기이다. IRM과는 달리 SMM은 상한값이 1로 제한되지 않는다.분리된 음성을 얻기 위하여, 우리는 SMM 또는 이것의 추정값을 노이즈 음성의 스펙트럼 크기에 적용한다. 그리고 노이즈 음성의 페이즈와 분리된 음성을 재합성한다.
### E. Phase-Sensitive Mask
위상에 민감한 마스크, PSM은 위상의 측정을 포함해서 SMM을 확장한다. 여기에 세타는 TF 단위의 깨끗한 음성과 노이즈 음성의 위상 차이를 나타낸다. PSM에 위상 차이를 포함하는 것은 신호 대 잡음 비를 더 높인다. 그리고 SMM 보다 더 나은 깨끗한 음성의 추정치를 산출한다. 
### F. Complex Ideal Ratio Mask
복소수 기반 IRM은 복소수 도메인에서의 이상적인 마스크이다. 앞서 이야기한 마스크와는 달리, 이것은 완벽하게 노이즈 음성으로부터 깨끗한 음성을 재구성할 수 있다. (복소수라서) S, Y는 각각 깨끗한 음성과 노이즈 음성의 STFT 결과를 나타낸다. 그리고 *는 복소수 곱연산을 말한다. cIRM의 정의식을 보면 real Y와 imag Y가 있다. 이는 각각 노이즈 음성의 실수 성분과 허수 성분을 가리킨다. 마찬가지로 깨끗한 음성인 S에도 실수 성분과 허수 성분이 있다. 허수 파트는 “I” 라는 기호로 표시된다. 그리고 cIRM은 실수 성분과 허수 성분 모두 가진다. 또 실수 도메인에서 별도로 값을 추정할 수도 있다. 복소수 연산이기 때문에 마스크의 값은 경계가 없다. (제한이 없다.) 그래서 어떤 압측된 형태를 마스크 값에 적용해야 한다. 예를 들면 탄젠트 함수나 시그모이드 같이 말이다.
### G. Target Magnitude Spectrum
깨끗한 음성의 TSM, 또는 S(t, f)는 훈련 데이터에 기반한 매핑이다. 이러한 지도 학습 목표는 노이즈 음성으로 부터 깨끗한 음성의 크기를 추정한다. Power spectrum 또는 Mel spectrum 같은 형태가 Magnitude spectrum 대신에 사용될 수 있다.일반적으로 훈련을 쉽게 하고, 역동적인 범위를 압축시키기 위해 로그 연산이 쓰인다.잘 알려진 TMS 형태는 평균이 0으로 정규화된 Log power - spectrum이다. 계산된 음성의 magnitude는  잡음의 위상과 조합되어 분리한 음성의 파형을 생성한다. 비용 함수로는 MSE가 TMS 계산에 종종 쓰인다. 또는 결과의 상관관계를 명시적으로 모델링하는 TMS 계산기를 위해서는 최대우도 방법이 쓰인다.
### H. Gammatone Frequency Target Power Spectrum
GF-TPS 이라는 방법도 있다. 이 역시 mapping - based target에 기반한다. spectrogram에서 정의된 TMS와는 달리, 이것의 목표는 gammatone filterbank에 기반하는 cochleagram에서 정의된다. 구체적으로는 깨끗한 음성을 위한 cochleagram 반응의 세기에 달려있다. cochleagram의 역계산을 통하여 GF - TPS의 추정치는 분리한 음성 파형으로 쉽게 변환된다. 
### I. Signal Approximation  
신호 근사의 생각은 깨끗한 음성의 스펙트럼 세기와 추정된 음성과의 차이를 최소화하는 ratio maks estimator을 학습하는 것이다. SA(t, f)의 정의식에서 RM(t, f)는 SMM의 추정값을 말한다. 그래서 SA는 SNR 최소화를 추구하는 ratio masking과 spectral mapping의 조합된 목표로 해석할 수 있다. 이와 관련된 이전의 사례는 IBM 추정치의 맥락에서 SNR를 최대화하는 목표로 한다. SA 목표는 다음의 두 단계로 더 나은 성능을 보여준다. 첫 번째는 SMM을 목표로 학습하는 것이다. 두 번째는 손실 함수의 최소화로 학습을 미세 조정한다. 
### Training targets에 대한 결론
다양한 훈련 대상을 고정된 deep neural network를 사용하여 동일한 입력 데이터들로 비교하였다. 다양한 훈련 대상을 사용하여 분리된 음성은 STOI와 PESQ 조건에서 예측된 음성 명료성과 음성 품질을 평가한다. 게다가, 대표적인 음성 향상 알고리즘과 지도 기반 음수가 없는 matrix factorization 알고리즘이 벤치마크로 사용된다.  
> First, in terms of objective intelligibility, the masking-based targets as a group outperform the mapping-based targets, although a recent study indicates that masking is advantageous only at higher input SNRs and at lower SNRs mapping is more advantageous.
- 최근 연구는 masking이 오직 높은 SNR에서만 유리하고 낮은 SNR에서는 mapping이 더 큰 장점을 가지는 것을 보여주었지만,
  여전히 masking based targets이 mapping based targets을 능가한다.
> In terms of speech quality, ratio masking performs better than binary masking.
- 음성 품질 관점에서는 ratio masking이 binary masking보다 더 성능이 우수하다.
- SMM은 간섭 신호와 SNR에 민감하다. TMS는 간섭 신호와 SNR에 민감하지 않다.
- TMS의 디테일한 매핑은 SMM의 그것보다 추정이 더 어렵다. 그리고 스펙트럼 크기의 한계가 없는 것은 추정의 오류를 확대시킨다. 
> Overall, the IRM and the SMM emerge as the preferred targets. In addition, DNN based ratio masking performs substantially better than supervised NMF and unsupervised speech enhancement.
- IRM과 SMM이 선호된다. 심층 신경망 기반 ratio masking이 지도 기반 NMF와 비지도 음성 향상보다 더 우수한 성능을 발휘한다.
#
#
## IV. 특징
특징은 지도 학습에서 상호 보완적인 역할을 한다. 특징이 구분 가능하면, 학습하는 기계에 대한 의존도가 낮아진다. 반면에 강력한 학습 기계가 있다면 특징에 대한 의존도가 낮다. 
- 초기 음성 분리 연구에서는 몇 가지 특징만을 사용하였다.
- 후속 음성 분리 연구에서는 MFCC, GFCC, RASTA - PLP 등 더 다양한 특징들을 활용한다. 
#
저자는 낮은 SNR에서 음성 분리를 위하여, 광범위한 음향 특징을 조사하는 연구를 하였다. 특징들은 mel domain, linear prediction, gammatone domain, zero crossing, autocorrelation, medium time filtering, modulation, pitch based features 등이 있다.
- Mel domain은 MFCC와 DSCC로 mel spectrum에 델타 연산이 적용되는 것을 제외하고 MFCC와 비슷하다. 
- linear prediction 특징은 PLP, RASTA - PLP이다.
- gammatone domain의 세 가지 특성은 GF, GFCC, GFMC이다.
- 그 외 GF의 계산과, zero crossing, autocorrelation, medium time filtering, modulation domain features에 대한 이야기 
#
참고로 디노이징에서는 평가가 다음과 같이 수행되었다.비정적인 소음의 앞 절반을 훈련에 사용하고, 나머지 절반을 테스트에 사용했다. 그리고 일치하지 않는 완전히 새로운 소음을 테스트에 사용하였다.여하튼 지도 학습 기반의 음성 분리에서 특징을 추출하는 것은 중요하다. 또한 특징 추출을 하지 않은 원래의 파형 그대로를 사용하면, 분리 결과가 더욱 나쁘다. 그러나 주목할 것은 DNN은 파형 신호와 잘 맞지 않을 수도 있다. CNN, RNN 방법론은 엔드 투 엔드 모델에 잘 맞다. 
### A. Speech Enhancement
Wang and Wang이 2012년에 딥 러닝을 처음으로 음성 분리에 적용하였다. 그들은 어떤 DNN의 형태를 사용하도 우수한 음성 분리가 이루어졌다고 말하였다. 저널에 실린 그들의 논문에서는 서브밴드 신호를 얻기 위해 64 채널의 감마톤 필터뱅크를 통하여 신호를 입력했다. 입력 특징과 마지막 히든 레이어의 학습된 특징을 효율적으로 서브밴드 IBM을 추정하기 위하여 선형 서포트 벡터 머신으로 concatencated했다.
#
2013년 Lu의 논문에서는 오토인코더를 사용하여 음성 향상을 꾀하였다. 오토인코더는 비지도 학습의 한 종류이고, 일반적으로 대칭 네트워크 구조를 가진다. 입력된 신호를 자기 자신과 매핑하는 방법을 거친다. 이것은 노이즈 음성의 mel frequency 크기 스펙트럼에서 깨끗한 음성의 주파수로 매핑하는 방법을 학습한다. 이후 Xu의 연구에서는 노이즈 음성의 로그 파워 스펙트럼과 깨끗한 음성의 그것으로 사전 학습한 RBM이 있는 DNN을 사용하였다. DNN은 깨끗한 음성의 스펙트럼을 노이즈 음성의 입력으로부터 추정한다. 이 결과는 훈련된 DNN이 훈련되지 않은 노이즈가 낀 음성보다 더 나은 PESQ를 얻는다는 걸 보여준다. 그리고 전통적인 개선 방법에서 얻은 것보다 더 높다. 
#
많은 후속 연구들이 TF 마스킹과 스펙트럼 매핑에 관련하여 발표되었다. LSTM이 있는 RNN을 음성 향상과 신호 근사를 목표로 훈련하는 강건한 ASR로의 응용에 사용했다. 심층 신경망이 IBM 추정을 위해 쓰였고, pitch 계산을 위하여 mask estimation이 사용되었다. DNN은 동시에 cIRM에서 허수부와 실수부 연산에 쓰인다. 이는 IRM 추정보다 더 나은 결과를 보여준다. 현상학적 레벨에서 음성 향상은 최근에 연구되었다. DNN은 부분적인 획득 함수와 함께 지각 마스킹을 고려한다. 다양한 객체 학습이 성능의 향상에 도움이 된다. 서브밴드 스펙트럼 매핑을 학습하는 계층 DNN이 풀밴드 매핑을 수행하는 싱글 DNN보다 우수하다. 불연속적인 레이어 간의 스킵 커넥션이 성능을 높이기 위해 DNN에 쓰인다. 마스킹과 목표 기반 매핑 모두 갖춘 멀티 학습은 단일 학습보다 성능이 좋다. CNN 또한 IRM 추정과 스펙트럼 매핑에 쓰인다.
#
또 엔드 투 엔드 분리를 위해 딥 러닝을 사용한 최근의 사례는 TF 표현에 의존하지 않는다. 대신에 시간 매핑을 수행한다. 이러한 접근의 장점은 향상된 음성을 재건하기 위해 노이즈 음성의 위상을 사용해야 할 필요성을 없애는 것이다. 특히 SNR이 낮을 때, 노이즈 음성의 위상은 음성 품질의 저하를 만들 수 있다. 최근에 Fu는 FCN이 제거된 CNN을 개발했다. 그는 FCN이 모든 스펙트럼의 매핑을 어렵게 한다고 말한다. 그래서 이것을 없앴더니 결과는 향상했다. 컨볼루션 연산이 필터나 특징 추출기와 동일하기 때문에, 시간 매핑을 위한 자연스러운 선택으로 보인다.
#
또 최근 연구는 GAN을 시간 매핑에 응용한다. SEGAN의 generator는 완전한 CNN 구조인데, 음성 향상과 디노이징을 수행한다. discriminator는 같은 구조인데, 이것은 생성된 파형 대 깨끗한 신호의 정보를 다시 G로 보낸다. D는 G를 위해 훈련 가능한 손실 함수를 제공하는 셈이다. SEGAN은 훈련되지 않은 노이즈 환경에서 평가되지만, 결과는 마스킹이나 매핑 방법보다 나쁘다. 다른 GAN 연구로 G는 노이즈 음성의 스펙토그램을 향상시킨다. 반면에 D는 향상된 스펙토그램과 깨끗한 음성을 구별한다. 비교를 보면 GAN에 의한 결과가 DNN에 의한 그것과 비교할만 하다는 것을 보여준다. 심층 학습 기반 음성 향상이 모두 DNN 기반은 아니다. 예를 들어 Le Roux는 심층 NMF을 제안했다. 이것은 NMF 연산자를 펼친 것인데, 역전파 방법으로 다중 업데이트를 포함한다. Vu는 노이즈 음성의 NMF 활성 계수를 깨끗한 버전으로 만들도록 DNN을 교육하는 NMF 프레임워크를 제안했다. 
### B. Generalization of Speech Enhancement Algorithms
그 어떤 지도 학습에서든, 훈련되지 않은 조건에 대한 일반화는 중요한 문제이다. 데이터 기반 알고리즘은 일반화에 대한 입증을 해야하는 부담이 있다. 왜냐하면 이 문제는 전통적인 음성 개선이나, 지도 학습의 사용을 최소화하는 CASA 알고리즘에서 생기지 않기 때문이다. 지도 학습 기반 개선은 세 가지 관점이 있다. 노이즈, 화자 그리고 신호 대 잡음 비이다. SNR의 일반화에서는 훈련 셋트에 더 강한 SNR 레벨을 포함할 수 있다. 그리고 실험은 지도 학습 기반 개선이 훈련에 사용된 정확한 SNR에 민감하지 않다는 것을 보여준다. (그 이유는???)  
- 몇 가지 혼합한 SNR이 훈련에 포함될지라도, 프레임 레벨과 TF 단위에서 로컬 SNR은 대개 넓은 범위에 걸쳐 있다. 이는 학습 기계가 잘 일반화하기 위해 필수적인 다양성을 제공한다.
- 다른 전략은 낮은 SNR 조건을 다루기 위해 히든 레이어의 수를 증가시키는, 점진적 학습법을 채택하는 것이다.
#
훈련과 검증 조건 사이의 미스매치를 설명하는 노력으로, 하나는 스펙트럼 매핑을 수행하는 표준 DNN 모델이고 다른 하나는 테스트 단계 동안 오토인코더를 사용하는 모델이 있다. 오토인코더는 스스로 깨끗한 음성의 스펙트럼 세기를 매핑하도록 학습한다. 그래서 라벨데이터셋이 필요하지 않다.  오토인코더가 DNN 위에 있다. 그 이유로는 잘 개선된 음성은 작은 차이를 만들어 내지만, 그렇지 않은 음성은 큰 오류를 만들어내기 때문이다. 이것을 체크하는 것이 오토인코더의 목적. 
#
노이즈 일반화는 모든 정지 노이즈와 비정지 노이즈가 음성 신호를 간섭하기 때문에 더 어려운 문제이다. 훈련 가능한 노이즈가 제한되어 있을때 한 가지 방법은 노이즈 섭동을 통해서 훈련 노이즈를 확장하는 것이다. 특히 주파수 교란이 그렇다. 구체적으로 원시 노이즈 샘플의 스펙토그램은 새로운 노이즈를 만들기 위해 교란 되어진다. 새로운 노이즈에 강건한 DNN 기반 매핑 알고리즘을 만들기 위해, Xu의 논문에서는 노이즈 교육을 한다. 입력 특징은 명시적으로 노이즈 추정치를 포함한다. 이진 마스킹을 통하여 추정된 노이즈를 사용하여, 노이즈 교육을 받은 DNN은 새로운 노이즈에 대해 더 잘 일반화한다.
노이즈 일반화에서 DNN은 프레임 레벨에서 IRM을 추정한다. IRM은 연속적인 프레임에 걸쳐서 추정되며, 같은 프레임에서의 서로 다른 추정은 부드럽게 평균낸다. 일련의 실험들에서 다양한 노이즈를 이용한 훈련이 이를 일반화하는 강력한 방법임을 알수 있다. 특정 화자를 결정짓는 문제에서는 특정 화자에 대한 분리 시스템이, 다른 화자에게는 잘 잘동하지 않을 것이다. 이를 위한 직접적인 시도는 많은 수의 화자로 훈련하는 것이다. 그러나 실험 결과는 보통의 DNN이 많은 화자를 일반화 하기는 어려운 것 같다. 때때로 네트워크는 노이즈를 목표한 음성으로 오인하는 결과도 있다. RNN은 자연스럽게 시간 의존적인 모델링을 가능하게 한다. 그래서 DNN에 비해 화자 일반화에 더 유연할 것이다.
#
우리는 최근에 LSTM을 노이즈에 의존하지 않는 화자 일반화에 적용하였다. DNN은 화자가 많을수록 손해였지만, LSTM은 화자가 많을수록 이득이였다. LSTM은 학습 동안 많은 화자들에게 노출되면서, 실제로 목표 화자를 잘 추적할 수 있는 것 같다. 대규모 훈련과 많은 화자, 방대한 노이즈로 LSTM은 (RNN) 노이즈 비의존 음성 개선에서 좋은 성능을 보여주었다.  
### C. Speech enhancement and Denoising  
실제 환경에서, 음성은 음파의 표면 반사과 반향에 의하여 변질된다. 반향은 음성 처리에서 잘 알려진 어려운 문제이다. 특히 배경 노이즈와 결합할 때 더욱 그렇다. 결과적으로 무반향이 오랜 시간동안 연구되었다. 음성의 무반향에 쓰인 심층 신경망은 cochleagram 위에서 스펙트럼 매핑으로 접근한다. 다른 말로 DNN은 음성 프레임 반향의 윈도우를 무반향 음성의 프레임으로 매핑하는 쪽으로 훈련된다. 훈련된 DNN은 높은 품질로 cochleagram of anechoic speech를 재건한다. 후속 연구는 스펙토그램에 스펙트럼 매핑을 적용하고, 무반향과 디노이징 모두 수행하는 것으로 확장한다. 프레임 길이와 쉬프트가 반향 시간에 따라 다르게 선택되었을 때, 무반향 성능이 향상되는 것이 관찰되었는데 이를 통해 더 정교한 시스템이 가능하다.  이 시스템에서 T60이라는 파라미터를 계산한다. 이것은 특징 추출을 위해 적절한 프레임 길이와 shift를 선택한다. 
#
노이즈 음성과 반향에서 anechoic speech의 추정을 향상하기 위해 static, delta and acceleration features를 동시에 예측하도록 DNN를 훈련한다. static 특징은 깨끗한 음성의 로그 스케일 세기이다. 그리고 delta와 acceleration 특징은 이 static features로부터 획득한다. DNN에서 동적인 특징의 통합이 무반향을 위한 static 특징의 추정을 잘 하는데 도움을 준다. 또한 스펙트럼 매핑이 TF 마스킹보다 무반향에서 더 효과적인 사실이 알려져 있다. 반면에 마스킹은 디노이징에서 매핑 방법보다 낫다. 결과적으로 이 두 가지 방식이 DNN에 적용되었다. 하나는 디노이징을 위한 ratio masking을 수행한다. 둘은 무반향을 위한 스펙트럼 매핑을 수행한다. 더 나아가 향상된 음성의 파형 신호를 재합성할 때 반향성 - 노이즈 음성의 위상을 사용하는 것의 부작용을 완화하기 위하여, 시간 도메인에서의 신호 재구성 기술을 확장한다. 이러한 모델은 다른 매핑 또는 마스킹의 싱글 모델보다 성능이 우수하다. 
### D. Speaker Seperation
화자 분리의 목표는 둘 이상의 목소리가 섞인 신호에서 서로 다른 음성을 추출하거나, 특정 화자 한 명을 알아내는 것이다. 역시 심층 신경망이 엄청 유용하다. DNN은 성공적으로 음성 분리에 쓰였다. DNN가 쓰인 한 연구에서 he authors argue that the summation of the spectra of guaranteed to equal the spectrum of the mixture. Therefore, a masking layer is added to the network, which produces two final outputs shown in the following equations. 섞인 스펙트럼을 두 식에 합성곱을 한다. 이러한 방법은 신호 근사에 해당한다. 특히 IBM과 IRM이 모두 효과적이다. 각각의 출력에 대해서 라벨링 스펙트럼이 존재하고, 마스킹 레이어와 차별한 훈련 모두 음성 분리를 개선한다. 별개로 또 다른 연구는 cochannel mixture에서 목표 화자의 로그 스케일 파워 스펙트럼을 학습한다. 또 다른 논문에서는 DNN이 cochannel 신호를 간섭 화자의 스펙트럼 뿐만 아니라 목표 화자의 스펙트럼에서도 매핑한다.
#
음성 분리에서 본질적인 화자가 훈련과 검증에서 바뀌지 않는다면, 이것은 화자에 의존하는 상황이다. 만약에 간섭하는 화자가 바뀌지만, 목표 화자는 고정이라면, 이것은 목표에 의존하는 음성 분리이다. 훈련과 검증에서 화자가 꼭 똑같아야 할 이유가 없는 경우에는 완전히 화자에 독립적인 상황이다. 이러한 관점에서 Huang의 접근은 화자 독립이다. 또 방해하는 화자의 제약을 완화하여, 단순하게 방해 화자와 목표 화자를 섞어서 훈련하기도 한다. Zhang, Wang은 화자 의존 뿐만 아니라 목표 의존 분리를 위한 앙상블 네트워크를 제안한다. 앙상블은 다양한 모듈을 쌓은 구조이다. 화자 의존 음성 분리에서는 신호 근사가 효과적이었다. 목표 의존 음성 분리에서는 비율 마스킹과 신호 근사의 조합이 효과적이다. 더 나아가서 목표 의존 음성 분리의 성능은 화자 의존 음성 분리의 그것과 가깝다.
#
Healy는 최근에 화자에 의존하는 cochannel 분리에 DNN을 사용하였다. 그리고 HI, NH 청자들에게서 DNN의 음성 명료성 평가를 수행하였다. DNN은 IRM과 목표 화자나 간섭 화자에 해당하는 특징을 학습하였다. 이 알고리즘은 다양한 IRM 프레임의 예측과 특징을 사용한다. 결과적으로 분리를 잘 했다. 
화자에 의존하지 않는 음성 분리는 비지도 군집 학습으로 다루어 질 수 있다. TF 단위는 각 개인의 화자에 의해 지배되는 개별 클래스로 클러스터링 된다. 클러스터링은 많은 수의 화자를 분리하기에 유연한 프레임워크이다. 그러나 지도 학습에 충분히 쓰이는 구별 가능한 정보를 쓰는 것만큼 장점이 있지는 않다. Hershey 등은 최초로 화자에 의존하지 않는 멀티 토커 분리를 DNN을 이용하여 소개하였다. 그들은 DNN 기반의 특징 학습과 스펙트럼 클러스터링으로 조합한 심층 클러스터링으로 불린다.
#
(중간 과정을 건너 띄고)
주목해보아야 할 것은, 스피커 분리 평가가 전형적으로 두 스피커의 혼합에 초점을 둘지라도 분리 프레임워크는 2명 이상의 토커를 분리하기 위해 일반화될 수 있다. 예를 들어 12, 14의 다이어그램에서 3명의 토커를 다루기 위해 확장할 수 있다. 멀티 스피커 음성을 사용하여 목표에 의존하지 않는 모델을 훈련할 수 있다. 스피커에 의존하지 않는 분리를 위해서는 딥 클러스터링과 순열 치환 방식 모두 멀티 토커 음성에 공식화되어 있고, 그러한 데이터를 평가한다. 
#
이 스피커 분리 섹션의 통찰에서 꽤 많은 스피커들로 훈련된 심층 신경망은 훈련에 포함하지 않은 스피커들도 잘 분리하는 것을 보여준다. 프레임 레벨에서 스피커에 의존하지 않는 경우, 어떻게 각 개별 프레임에서 잘 분리된 음성 신호를 그룹화할 것인지의 문제가 있다. 이것은 정확히 시퀀스 구성적인 문제로 CASA으로 많이 조사한다. 순열 치환 방식은 심층 신경망이 훈련하는 동안, 순차적으로 그룹화 제한 조건을 부과하는 것으로 생각할 수 있다. 반면에 전형적인 CAS 방법은 피치 등고선, 보컬의 특성, 리듬 또는 운율이나 다양한 센서를 사용할 때 흔한 공간 방향까지 활용한다. 이것은 지도 학습까지 필요로 하지는 않는다. 우리가 보기에 전통적인 CAS 기술과 딥 러닝을 통합하는 것은 미래 연구의 중요한 기반이다. 
