# End-to-End Model for Speech Enhancement by Consistent Spectrogram Masking
# Abstract
최근에 페이즈 처리가 스피치 향상 분야에 큰 흥미를 불러 일으켰다. 어떤 연구자들은 페이즈 추정 모듈을 스피치 향상 모델에 STFT의 복소수 기반 training target을 사용하여 적용했다. 예를 들어 complex ratio mask같은 것이다. 그러나 스펙트로그램의 마스킹은 일관성의 제약 조건을 파괴할 수도 있다. 이 연구에서 우리는 이 일관성이 깨지는 문제가 스피치 향상 모델의 solution space를 키우고, 의도하지 않은 artifacts을 야기한다. Consistency Spectogram Masking은 일관성 제약조건을 가지는 신호의 complex spectrogram을 추정하기 위해 제안되었다. 이 방법은 간단하지만 그렇다고 하찮은 것은 아니다. 우리의 CSM 기반 엔드 투 엔드 모델을 다른 방법과 비교한 실험은 CSM이 모댈의 훈련을 가속하고, 음성 품질을 충분히 개선하는 것을 보여준다. 이 실험으로부터 우리의 방법이 노이즈 음성을 능률과 효율성 측면에서 낫다는 것을 확실하게 보여줄 것이다.
- 신호를 STFT하여 얻는 복소수 기반 complex ratio mask는 일관성의 제약 조건을 무너뜨릴 수 있다. 
- 이 일관성이 무너지는 문제는 스피치 모델의 솔루션 경우를 늘려버리고 부작용도 생긴다. (솔루션이 많아지는 것은 컴퓨터에게 좋지 않음)
- 그래서 일관성을 가지는 스펙트로그램 마스킹을 제안한다. 이것은 일관성 조건을 유지하는 complex sptectrogram을 추정한다.

# Introdunction
- 많은 오디오, 음성 처리에서 자주 사용되는 신호 표현 방법이 STFT이다.
- 그러나 연구자들이 STFT의 모델링과 magnitude에만 집중하기 때문에 phase는 자주 무시당했다.
- 재구성을 원한다면, phase 정보는 필수적이다. magnitude가 변하면, 신호 복구를 위한 원래의 위상를 가져다 쓰기에 충분하다. 그래서 이것은 원치 않은 부작용을 발생시킨다.
- 몇몇 연구자들은 이 original phase가 응용될 수 없는 것에 초점을 맞추었다. 이 경우에 STFT phase 복원 알고리즘은 수정된 magnitude로부터 유효한 phase를 만들어낸다. 이는 기존의 phase를 완전히 사용할 수 있는 것을 허용한다. 
- 최근의 연구자들은 magnitude와 phase responses를 동시에 개선하는데 관심을 둔다. 
- 만약 spectrogram이 수정되면, 이것은 더이상 STFT의 그 어떤 time - domain signal하고도 일치하지 않는다. 이를 inconsistent sptectrogram이라 부른다.
- 대부분의 음성 향상 접근법은 오직 magnitude를 바꾸고, complex spectrogram을 추정할 뿐, 이것은 결국 inconsistent spectrogram을 일으킬 것이다.
- STFT에서 얻은 consistent spectrogram은 complex spectrogram에서 극히 일부라는 것이 명심해야 한다.
- 우리는 consistent spectrogram에서 실수부와 허수부를 동시에 재건하는 알고리즘을 제안한다, 다시 말해, 어떤 노이즈 음성의 complex spectrum이 주어지면, 깨끗한 음성의 consistent spectrum으로 복원할 수 있다. consistent spectrogram 공간에서 우리 방법의 최적화 공간이 제한적이기 때문에, 빠른 수렴 비율과 높은 정확도를 성취할 수 있다. 
# Masking method Incosistent spectrogram problems
- 음성 향상에서 흔한 셋업은 STFT 해석과 주파수 조정, 그리고 곧 이어 Inverse STFT이다. 
- 이 분야에서 복소수 처리가 Phase Sensitive Masking, Complex Ratio Masking와 같이 큰 영향을 주고 있다.
- 위에서 말했듯 inconsistent spectrogram problem이 있다. 이는 음성 향상에서 도전적인 문제이다.
- STFT 해석이 겹쳐지는 윈도우를 사용하기 때문에 개별 신호 성분의 어떤 변화가 다양한 STFT 주파수 위치와 다양한 프레임에 넓게 퍼지게 된다.  
(STFT의 변환 커널이 겹쳐지면서 shift하기 때문에 magniftude의 정보가 변환한 도메인의 여러 지점에서 영향을 준다는 말일까???)
- S(t, f)을 생각해보자. 이것은 복소함수인데, t는 프레임 인덱스이고 f는 주파수 밴드 인덱스이다. W는 프레임 shift R에 대해서 완벽한 복원 조건을 하게 해주는 커널 함수이다. 이때 우리는 그 어떤 complex spectrogram S에 대해서 다음과 같은 식을 얻는다.
[image1](https://github.com/Doyosae/Speech_Enhancement/blob/master/image/03_5.png)
- S는 S con, S incon로 쪼갤 수 있다. 이때 S incon를 ISTFT하고 STFT하면 S con와 같다. 그러나 다시는 S incon와 같지는 않다. 이 말은 S incon이 존재하는 공간이 S con보다 훨씬 크다는 이야기이다.
- 그래서 깨끗하게 추정한 음성 S hat은 자꾸 S2의 영역으로 떨어지는 경향이 생긴다. 
- 흔히 무시되는 불일치 스펙트로그램 문제는 겹쳐진 프레임이 불일치한 까닭에 재구성한 신호에서 artifacts를 만들어내지 못한다.
- 뿐만 아니라 incomsistent spectrgram space의 확장 때문에 모델 수렴이 어려워지는 것에도 한 몫한다.
## Consistent Spectrogram Masking
- 많은 음성 향상 모델은 추정된 clean speech의 spectrogram과 라벨링된 음성 x의 STFT 차이로 정의한 목적 함수를 를 최소화하는 것이다.
- 추정된 음성 S hat은 노이즈가 낀 음성이 비선형 관계를 거쳐오면서 도출된다. 이러한 비선형 성은 프레임 간의 유사성을 무너뜨리고 결국 S hat의 일관성을 보증하지 못한다. 
[image2](https://github.com/Doyosae/Speech_Enhancement/blob/master/image/03_4.png)
- 이는 spectrogram에 기반한 목적 함수의 inconsistent problem를 발생시킨다. 위의 과정을 따라가면 목적 함수가 다른 형태로 나온다. 저자는 time domain과 consistent spectrogram 에서 두 식이 동등하다고 말한다. 따라서 저자는 자연스럽게 뒷 식을 Obejctrive Function으로 고려하게 되었다.
내가 이해한 것 S hat은 Spectrogram에서의 도메인이고 STFT(x)도 Spectrogram에서의 도메인이다. 이를 조금 조작하면 ISTFT(S hat con)와 x에서의 차이로 유도된다. 이는 Spectrogram 도메인에서 time 도메인으로의 표현이 바뀔 수 있음을 말한다.
- S hat con와 S hat이 서로 다르더라도, 이것의 Invers STFT는 같다. 
- Griffin Lim의 알고리즘에서 페이즈 정보는 오직 스펙트로그램의 magnitude에서 얻어지지만, 그럼에도 불구하고 우리의 방법은 consistent spectrogram의 복소수에서 magnitudede와 phase information을 모두 추정한다. (무슨 말일까?)
- 여기에서 우리는 노이즈 음성 Y(t, f)의 복소수 스펙트로그램으로부터 따라오는 CSM을 정의한다.
## The framework of our proposed end-to-end model
[model](https://github.com/Doyosae/Speech_Enhancement/blob/master/image/03_1.png)
- CNN 구조는 음성 향상에도 매우 탁월한 성능을 발휘했다. 그러나 여기에는 tradeoff가 있는데, 커널 사이즈가 크면 더 넓은 영역에서의 맥락을 추출할 수 있지만, 낮은 해상도의 정보는 얻지 못한다. 그래서 완전히 CNN으로 연결한 구조를 사용하고, 다양한 사이즈의 특징들을 학습할 것이다.
- backbone 모델로 DenseNet을 이용하였고, 그 전에 앞서 Quasi Layer를 도입하였다. 이것은 STFT 레이어인데 2개의 1차원 컨볼루션 네트워크로 이루어져 있다. 각각 실수부, 허수부 파트를 맡아서 이산 푸리에 변환 커널로 역할을 수행한다.
[image3](https://github.com/Doyosae/Speech_Enhancement/blob/master/image/03_2.png)
- Quasi - ISTFT 레이어 또한 위와 유사하다. 이 모듈들은 보통의 컨볼루션 레이어로 구현하였고 따라서 신경망 모델과 통합하기가 매우 쉽다.
- Quasi Layer는 두 가지 장점이 있다. 첫 번째는 consistent spectorgram에서 objective function 정의하기 위한 확률을 제공한다 . 또 다른 점은 엔드 투 엔드 모델에서 STFT, ISTFT을 통합한 것이 역전파로 학습 가능한 푸리에 변환 커널을 만들 수 있다는 것이다.
원래는 신호를 푸리에 변환하고 Spectogram 도메인에서 학습한 후에, 다시 역변환을 하여 Enhanced된 신호를 본다. 그래서 변환 커널은 학습할 수 있는 파라미터들이지는 않았다. 왜냐하면 신경망 레이어 바깥이기 때문이다. 그런데 이 논문에서는 1차원 컨볼루션 신경망을 sin, cos의 real, imagnary 파트로 초기화해서 학습 가능한 커널 변환으로 만들었다.
