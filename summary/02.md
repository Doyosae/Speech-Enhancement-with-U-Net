# Scaling Speech Enhancement in Unseen Environments with Noise Embeddings (Gil Keren, Jing Han, Bjo ̈rn Schuller)
## Abstract
이 논문에서는 두 가지 조작을 수행하여, 이전에 보지 못한 환경에 대한 음성의 일반화 문제를 다룬다. 첫 번째는 단독 환경에서만의 추가적인 녹음을 임베딩한다. 그리고 이 임베딩을 음성을 강화하는 서브네트워크의 활성을 바꾸기 위해 사용한다. 두 번째는 훈련에 사용한 노이즈 환경의 수를 16,784개의 다른 환경으로 규모를 키운다.  
## Introduction
실제 환경은 매우 다양하다. 그래서 스피치 개선 모델이 훈련 때 시도해보지 않은 처음 보는 환경에 대해서도 성능이 좋아야 한다고 가정해야 한다. 음성 개선의 기존 방법들은 소수의 환경이나 서로 유사한 환경에서 초점을 맞추었지만, 반대로 우리는 다양한 환경에서 음성 개선을 할 수 있는 스피치 모델을 목표한다. 이 많은 환경들이 훈련에 사용하였던 그것과는 상당히 다르다.  
첫 번째로 원 샷 러닝에서 아이디어를 얻어, 우리는 이 작업에서 사용된 노이즈 환경들을 서로 연관없는 카테고리로 생각하지 않았다. 오히려 모든 노이즈 환경을 포함하는 거대한 공간에서 뽑은 샘플들로 생각하였다. 이것은 처음 보는 소음 환경에서 음성 개선을 잘하는 것이 곧 소음 환경이 모여 있는 공간에서 한 번도 보지 못한 지점에서의 일반화에 해당하는 것이라고 말할 수 있다. 좋은 일반화를 수행하기 위해서 먼저 훈련 데이터를 늘렸다. 16,784개의 잡은 환경과 360 시간의 깨끗한 음성을 서로 다른 SNR 가지는 경우들로 마구마구 섞었다.  
더 나아가서, 우리는 네트워크에 동일한 환경에서의 추가적인 녹음을 제공하는 것이 어떤 주파수를 제거하고, 어떤 주파수를 강화해야 하는지 구분하는데 도움이 된다고 가정했다. 구체적으로 우리는 잡음이 낀 음성 세그멘트와 동일환 환경에서 모델을 음성이 없는 추가적인 녹음으로 우리의 모델을 조건화한다. 특정한 목적으로 만들어진 서브네트워크는 노이즈 임베딩을 만들기 위해 추가적인 녹음을 처리한다. 이것은 main enhancement network의 모든 레이어에 연결된다. 꽤 그럴듯한 시나리오이다. 장치는 노이즈가 낀 음성을 녹음하기 전에, 먼저 환경의 샘플을 녹음할 것이다. (내가 이해한 것 : 잡음이 낀 음성에서 잡음을 죽이고 음성을 강화하기 위해 미리 환경만의 잡음을 녹음해서 노이즈를 임베딩한다. 그리고 이를 각 네트워크에 입력해서 어떤 노이즈인지 조건화한다.)  
#
![model](https://github.com/Doyosae/Speech_Enhancement/blob/master/image/02.png)
#
### Embedding subnetwork
- 노이즈 임베딩을 위해 임베딩 서브네트워크를 사용하여 노이즈 세그멘트를 수행한다.  
- 처음 두 개의 residual blocks은 8 x 4 커널 사이즈, 3 x 2 스트라이드
- 마지막 두 개의 residual blocks은 4 x 4 커널 사이즈, 각각 1 x 1, 1 x 2 스트라이드
- feature map은 차례대로 64 128 256 512
- 마지막 512개의 특징 맵에서, 각각의 특징 맵들을 모둔 픽셀에 대하여 평균한다. 512개의 노이즈 임베딩 벡터를 얻음
### Enhancement subnetwork  
강화 서브네트워크는 향상된 음성 프레임을 결과로 내놓기 위해 노이즈 음성 세그멘트와 노이즈 임베딩을 수행한다. 이 서브네트워크는 세그멘트를 수행하는 8개의 레지듀얼 블럭으로 이루어져 있다. 레지듀얼 네트쿼으 각각은 컨볼루션 신경망이다. 노이즈 임베딩은 선형적으로 컨볼루션 레이어의 피처 맵 수와 동일한 차원에 투영된다. 그러고나서 투영된 노이즈 임베딩은 컨볼루션의 출력층 각각의 위치에 추가된다.  
- 이 네트워크는 향상된 음성을 출력하기 위해, 노이즈 임베딩과 노이즈 스피치 세그먼트를 수행한다.
- 8개의 residual network로 이루어져 있다. 노이즈 임베딩은 CNN의 특징맵 수와 같은 차원으로 투영된다.
- 투영된 노이즈 임베딩은 컨볼루션 레이어의 출력층에 픽셀끼리 합한다.
- 서로 다른 주파수 성분과 시간대를 각각 처리하기 위해서, time step과 frequency components를 색인화해서 각 컨볼루션 출력층의 적절한 위치에 추가했다. 이 색인 임베딩은 작은 뉴럴 네트워크를 통하여 나온다.
- 이 네트워크의 입력은 시간 / 주파수 축에서 적절한 위치를 나타내는 단일 정수이다.
- 50차원의 FCN을 거쳐, recitified linear activation function과 batch nomarlization을 적용한다.
- 이 네트워크의 residual block은 embedding subnetwork의 그것과 동일하다. 
- 처음 네 개의 residual blocks은 4 x 4 커널을 사용하고 나머지 blocks은 3 x 3 커널 사이즈이다.
- 2 x 2 스트라이드를 3, 5, 7번 블록에 적용한다. 
- 1, 2번 블록은 64개의 특징 맵, 다음에는 2 블록마다 묶어서 각각 128, 256, 512개의 특징 맵을 쓴다.
- 이 네트워크의 최종 출력은 flatten을 쓰고, 201개의 출력으로 FCN을 적용한다. 이 레이어의 출력은 곧 enhancement mask이다.
- 이 마스크를 노이지 스피치 세그멘의 프레임에 더해서, 향상된 프레임을 산출한다.
- 훈련하는 동안 네트워크는 mean squeared error로 개선된 프레임과 깨끗한 음성 라벨 사이을 쵲거화한다. (Loss function)
- 실험에서는 SGD (learning rate = 0.1)에서 가장 성능이 좋은 것을 보았다. (Loss function을 최적화 하는 방법)
