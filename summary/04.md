# Towards Generalized Speech Enhancement with Generative Adversarial Networks 
#
## Abstract
Speech Enhancement는 보통 noise의 제거나, 불완전한 발성으로 생기는 reverberation를 제거하는 작업으로 이루어져 있습니다. 
그러나 클리핑이나 청크 제거나 또는 주파수 밴드가 통째로 사라지는 문제에는 관심이 비교적 적었. 
이러한 왜곡은 음성의 명료성 뿐만 아니라 자연스러움 심지어 화자의 식별까지 어려울 수 있습니다. 
이 작업에서 우리는 일반화된 스피치 개선을 위해 완전히 새로운 방법을 고려하고 있습니다. 
그리고 이것은 시간 도메인 Generative Adversial Model이 힘든 씨름이 되는 것도 보여줍니다. 
특히 우리는 이전의 GAN 기반 스피치 개선 시스템을 네 가지의 공격적인 왜곡을 바로잡기 위하여 확장하였습니다.
- Discriminator가 보다 풍부한 특징을 학습할 수 있도록 adversarial acoustic regression loss를 제안합니다.
- 두 단계의 GAN 훈련 과정을 준비 및 모델 학습의 준비 및 모델의 finetuning 과정에서 사용합니다.
- 객관성과 주관성 평가 모두,  화자의 식별과 음성 자연스러움 측면에서 스피치 복원 성능이 크게 향상되는 것을 보여줍니다.
#
## Generalized Speech Enhancement 
이 연구에서는 고전적인 디노이징 작업에서 출발하여, 음성 개선 문제의 더 일반적인 단계까지 고려합니다. 
더 구체적으로, 우리는 다양한 signal manipulation으로  손상된 음성 복원 문제를 고려합니다. 
이러한 방식으로 손상된 음성들은 청각으로 알아듣기가 매우 곤란합니다. 
우리는 훈련하는 동안 몇몇 speaker와 이러한 signal manipulation을 서로 섞었습니다. 
동시에 각 스피커들의 구성 요소를 복원할 수 있는 알고리즘을 학습할 수 있다고 생각합니다. 
이 방법은 첫 번째로 음성 개선을 위한 근사론입니다. 우리는 다음의 signal manipulation을 고려하였습니다.
- Wihspered speech : 이것은 WSEGAN 연구에서 소개되었던 왜곡입니다. 
그러나 이것은 마그네틱 센서를 사용하지 않는 것에서 차이가 있습니다. 
우리는 whispering speech를 vocoder와 함께 깨끗한 음성으로 인코딩하는 방법으로 합성하였습니다. 
여기에서 log F0를 제거하고, whispers 형태의 신호로 복원하였습니다. 
더 나아가 인위로 목소리를 제거했습니다. 사용된 vocoder는 기본 파라미터가 설정된 Ahocoder입니다.
- Bandwith Reduction : 우리는 x2에서 x8의 서로 다른 심각성 요인을 가진 오디오 신호를 다운 샘플링합니다. 
이것은 bandwidth를 줄이는 것입니다. 
그러고 나서 일반화된 개선 모델은 깨끗한 음성으로의 훈련을 거쳐 전체 주파수 밴드를 복원해야만 합니다. 
- Chunk removal : 음성이 포함된 파형에 무작위로 청크의 수를 사일런스를 넣어서 제거합니다. 
그래서 우리는 음성이 포함된 시간 도메인에서 신호를 없애버립니다. 사일런스의 길이는 다음의 두 분포에서 샘플링됩니다. 
- 클리핑 : 파형이 전체적으로 발성의 maximum abosolute peak에서 상대적인 손상도에 따라 잘라냅니다. 
그래서 새로 만든 신호는 진폭 범위의 왜곡이 되지 않는 적절한 범위에서 신호를 재조정 해야합니다.
## Acoustic Mapping Discriminator 
- 현재 존재하는 SEGAN의 구조를 살짝 바꾸었습니다. 
지금부터 소개하는 acoustic loss라는 개념과 이러한 로스를 적용하기 위해 두 단계의 훈련 스케쥴입니다.
#
![model](https://github.com/Doyosae/Speech_Enhancement/blob/master/image/04_1.png)
### Acoustic Loss
- 일반적으로 D는 학습 가능한 로스 함수로 이해됩니다. D는 우리가 생성하고 싶은 실제의 특징은 역전파 과정에 내포하고 있습니다.
- G는 D의 gradient flows으로 성능이 향상됩니다. 이것은 D가 강력한 특징 추출기로 작동하게 합니다. 
왜냐하면 D가 추출한 특징의 품질이 좋을수록 G 역시 더 현실적인 특징을 잘 모사하기 때문입니다. 
- D에서 auxiliary classifying labels를 사용하는 것은 유용합니다. 
추가적으로 멀티 작업 준비는 생성 모델의 성능을 가속합니다. 
거기에는 신호의 다양한 인자들이 생성 모델의 결과물에서 예측되어, 신호의 더 나은 지각적 특성을 모델링합니다. 
이것은 disciminator가 단지 real or fake 결정만을 할 뿐, 신호 복원을 위해 중요한 특징은 고려하지 않는 SEGAN과 같은 모델에 적용할 수 있습니다.
- 또한 우리는 G에서 비롯하는 추가적인 regularization loss를 D에서 비롯하는 adversarial loss와 종합할 수 있습니다. 
예를 들어 초기 버전의 SEGAN에서는 G의 출력을 zero centered siganl로 만드는 L1 규제 항을 사용하였습니다. 
그리고 그 다음의 WSEGAN 구현은 이것을 덜 제한적인 power loss로 대체했습니다. 
이는 주파수 밴드에서 적절한 에너지 할당을 하였습니다.
- 이제 D의 끝단에서 새로운 가지를 여는 acoustic loss를 제안합니다. 
이것은 D가 필수적으로 추가적인 acoustic components를 인지하게 해줍니다. 
이 acoustic components는 G에게 중요한 실수를 알려줍니다. 
예를 들어 복원된 음성의 ID, 억양, 내용이 일치하지 않을 때 등입니다. 
이 과정은 G의 입력에 왜곡된 신호를 제외하고서 어떠한 추가적인 입력도 필요하지 않습니다. 
- 이러한 방식은 G의 일반화 측면에서 제약 조건을 피할 수 있다는 장점이 있습니다. 
그 어떤 종류의 정보나 신호의 타입, 누구인지 가능한 클래스에 의해 제한되는 어떤 코드도 넣지 않았기 때문입니다. 
새로운 D의 출력은 convolution 구조의 특정 레벨에서 갈라집니다. 
이 구조는 time decimation factor가 256에 해당합니다. 그래서 각 시간 마다의 STFT에 해당합니다. 
각 프레임의 출력에서 이것은 log power spectral bins, MFCC, prosodic features의 concat을 예측합니다.
- 우리는 loss를 특징들의 모음으로 사용하여 디자인했습니다. 
왜냐하면 우리는 그것들이 다양한 음향 신호들을 적절하게 전달할 것이라는 생각엥 가설을 세웠기 때문입니다. 
이 가지는 진짜인지 가짜인지 알려주는 이진 출력에 연결됩니다. 그리고 입력 X에 대해서 이진 출력이 real 일때만 활성화됩니다. 
제안된 acoustic loss와 power regularization은 다음과 같은 로스 함수로 재정의합니다.
### Adversarial Pre-Training 
- SEGAN은 오직 adversarial loss만 사용하여 안정적인 평형을 학습했습니다. 
반면에 addition of the acoustic losses들은 훈련하는 도중 일부러 특정한 불균형 효과를 유발합니다. 
D의 항은 더 빨리 배우고 두 로스 모두 빠르게 수렴합니다. 반대로 G는 수렴 속도가 느립니다. 
중요한 것은 G와 D 모두 서로가 평형을 유지해야합니다. 그래서 둘 중 하나는 좀 빠르게 지치게 하되, 다른 하나는 꾸준히 잘 수행하도록 해야합니다.
- Discriminator의 학습 스케쥴링을 두 단계로 나누는 것이 acoustics loss의 효과를 더 올릴 것이라고 가정합니다. 
첫 번째로 고수준의 표현 분류를 하고, 그 다음에는 회귀를 통해 특정한 언어 속성에 초점을 둡니다. 
따라서 우리는 처음에 D에서 사전 훈련을 한 다음, acoustic loss를 추가합니다.
